#!/usr/bin/env bash
# SEALED: Ingestion-Orchestrator. Änderungen nur nach expliziter Rückfrage und architektonischer Prüfung.
set -euo pipefail
cd "$(dirname "$0")"
if [[ -f .env ]]; then set -a; source .env; set +a; fi

usage(){ cat <<U
Usage: $0 <command> [args]
  up       # start mgmt + crud
  mgmt     # start managementstudio
  crud     # start static CRUD server
  churn    # run churn auto processor (use ARGS via Makefile)
  down     # shutdown mgmt + crud (kill ports)
  open     # open browser tabs for mgmt + crud
  env      # print env
U
}
cmd=${1:-}; shift || true

case "$cmd" in
  up)   "$0" mgmt & "$0" crud & wait ;;
  mgmt)
    # Ermittele Verzeichnisse relativ zum Repo-Root, unabhängig von .env
    REPO_ROOT="$(cd .. && pwd)"
    UI_MGMT_DIR="${REPO_ROOT}/ui-managementstudio"
    BL_CHURN_DIR="${REPO_ROOT}/bl-churn"
    JSON_DB_DIR="${REPO_ROOT}/json-database"
    export MGMT_OUTBOX_ROOT="${BL_CHURN_DIR}/dynamic_system_outputs/outbox"
    export MGMT_CHURN_DB_PATH="${BL_CHURN_DIR}/dynamic_system_outputs/churn_database.json"
    cd "${UI_MGMT_DIR}"
    # Sicherstellen, dass eine venv existiert
    VENV_DIR="${UI_MGMT_DIR}/.venv"
    PYTHON_BIN="${VENV_DIR}/bin/python3"
    if [[ ! -d .venv ]]; then
      python3.11 -m venv .venv
      source .venv/bin/activate
      pip install -U pip
      if [[ -f requirements.txt ]]; then pip install -r requirements.txt; fi
    else
      source .venv/bin/activate
    fi
    # Pythonpfad für Module mit eigenem config/paths_config.py ergänzen
    export PYTHONPATH="${BL_CHURN_DIR}:${JSON_DB_DIR}:${PYTHONPATH:-}"
    # Stelle sicher, dass Dependencies vorhanden sind (Flask etc.)
    if [[ -f requirements.txt ]]; then pip install -r requirements.txt >/dev/null 2>&1 || true; fi
    "${PYTHON_BIN}" app.py
    ;;
  crud) cd "${UI_CRUD_DIR}" && python3 -m http.server 8080 ;;
  churn) export PYTHONPATH="${BL_CHURN_DIR}:${BL_COX_DIR}:${BL_CF_DIR}:${JSON_DB_DIR}:${PYTHONPATH:-}"; cd "${BL_CHURN_DIR}" && source .venv/bin/activate; python bl/Churn/churn_auto_processor.py ${*:-} ;;
  ingest)
    # Optionale Argumente parsen (z. B. --override <filename>)
    OVERRIDE_FILE=""
    while [[ ${1:-} ]]; do
      case "$1" in
        --override)
          OVERRIDE_FILE="${2:-}"
          shift 2 || true
          ;;
        *) shift || true ;;
      esac
    done
    # Ermittele Repo-Root relativ zu bl-workspace, ohne .env-Abhängigkeit
    REPO_ROOT="$(cd .. && pwd)"
    BL_INPUT_DIR="${REPO_ROOT}/bl-input"
    BL_CHURN_DIR="${REPO_ROOT}/bl-churn"
    JSON_DB_DIR="${REPO_ROOT}/json-database"
    export PYTHONPATH="${BL_INPUT_DIR}:${BL_CHURN_DIR}:${JSON_DB_DIR}:${PYTHONPATH:-}"

    # Stelle venv 3.11 sicher
    if [[ ! -d "${REPO_ROOT}/.venv311" ]]; then
      python3.11 -m venv "${REPO_ROOT}/.venv311"
    fi
    source "${REPO_ROOT}/.venv311/bin/activate"

    # Stelle Ausgabeverzeichnisse sicher
    mkdir -p "${BL_CHURN_DIR}/dynamic_system_outputs/stage0_cache" "${BL_CHURN_DIR}/dynamic_system_outputs/outbox"

    OVERRIDE_FILE="$OVERRIDE_FILE" python - <<'PY'
import sys
import os
from pathlib import Path
repo_root = Path(__file__).resolve().parents[1]
sys.path.extend([
    str(repo_root / 'bl-input'),
    str(repo_root / 'bl-churn'),
    str(repo_root / 'json-database'),
])
os.environ['OUTBOX_ROOT'] = str(repo_root / 'dynamic_system_outputs' / 'outbox')
from input_ingestion import InputIngestionService
from bl.json_database.churn_json_database import ChurnJSONDatabase

service = InputIngestionService()
csv_dir = repo_root / 'bl-input' / 'input_data'
all_csvs = sorted([p for p in csv_dir.glob('*.csv')])

# Files-Registry laden und bereits registrierte input_data-Dateien ermitteln
db = ChurnJSONDatabase()
files_tbl = (db.data.get('tables', {}).get('files', {}).get('records', []) or [])
registered_input = { (r.get('file_name') or '') for r in files_tbl if (r.get('source_type') or '').lower() == 'input_data' }

override = os.environ.get('OVERRIDE_FILE') or ''
override = override.strip()

for p in all_csvs:
    name = p.name
    is_override = (override and name == override)
    is_new = (name not in registered_input)
    if not (is_new or is_override):
        continue
    sp, res = service.ingest_csv_to_stage0(
        p,
        force_reanalysis=bool(is_override),
        register_in_json_db=bool(is_new),  # vermeide doppelte input_data-Registrierungen
        export_to_outbox=True,
    )
    print('Stage0:', sp)
    print('Outbox:', res.get('outbox_path'))

# Union-Import in rawdata
print('Importing Outbox Stage0 → rawdata (union, replace=True) ...')
db.import_from_outbox_stage0_union(replace=True)
db.save()
print('Done.')
PY
    ;;
  down|shutdown)
    # Beende Prozesse auf Management Studio und CRUD Ports
    kill_port() {
      local PORT="$1"
      local PIDS
      PIDS=$(lsof -ti tcp:"${PORT}" 2>/dev/null || true)
      if [[ -n "${PIDS}" ]]; then
        echo "Stopping processes on port ${PORT}: ${PIDS}"
        kill ${PIDS} 2>/dev/null || true
        sleep 1
        PIDS=$(lsof -ti tcp:"${PORT}" 2>/dev/null || true)
        if [[ -n "${PIDS}" ]]; then
          echo "Force killing remaining on port ${PORT}: ${PIDS}"
          kill -9 ${PIDS} 2>/dev/null || true
        fi
      else
        echo "No process on port ${PORT}"
      fi
    }
    kill_port "${MGMT_STUDIO_PORT:-5050}"
    kill_port "${CRUD_PORT:-8080}"
    ;;
  open)
    MS_PORT="${MGMT_STUDIO_PORT:-5050}"
    CR_PORT="${CRUD_PORT:-8080}"
    # Öffne Management Studio (SQL/CRUD je nach MGMT_DEFAULT_UI)
    (open "http://127.0.0.1:${MS_PORT}/sql" >/dev/null 2>&1 || true)
    # Öffne CRUD-Static Server
    (open "http://localhost:${CR_PORT}/" >/dev/null 2>&1 || true)
    echo "Opened: http://127.0.0.1:${MS_PORT}/sql and http://localhost:${CR_PORT}/"
    ;;
  env)  env | egrep "^(OUTBOX_ROOT|BL_|JSON_DB_DIR|UI_|MGMT_)" | sort ;;
  *) usage; exit 1 ;;
esac
